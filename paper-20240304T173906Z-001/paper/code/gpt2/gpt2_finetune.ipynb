{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rithwik/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import device\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple dataset class\n",
    "class GearDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data.readlines()  # Read lines from the file\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "epochs = 10\n",
    "batch_size=1\n",
    "lr = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning function\n",
    "def fine_tune_gpt2(dataset, tokenizer, model, epochs, batch_size):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Create DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "    # Use tqdm for progress bar\n",
    "    total_steps = len(dataloader) * epochs\n",
    "    progress_bar = tqdm(total=total_steps, desc=\"Training\", unit=\"batch\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            labels = inputs[\"input_ids\"].clone()\n",
    "            labels[labels == tokenizer.pad_token_id] = -100  # Mask padding tokens\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            progress_bar.update(1)  # Update progress bar\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss}\")\n",
    "    progress_bar.close()\n",
    "\n",
    "    model.save_pretrained('/home/rithwik/paper/saved_models')\n",
    "    print(f\"Fine-tuned model saved at: {'/home/rithwik/paper/saved_models'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gear data\n",
    "prompts = [\n",
    "    \"Design a gear with 20 teeth for a load of 1000N.\",\n",
    "    \"Design a gear for a speed of 500rpm and torque of 200Nm.\",\n",
    "    \"Design a gear to transmit power of 5kW at an efficiency of 90%.\",\n",
    "\n",
    "    # **Type and Material:**\n",
    "    \"Design a bevel gear made of stainless steel with a gear ratio of 2:1.\",\n",
    "    \"Design a helical gear made of nylon with a pressure angle of 20 degrees.\",\n",
    "    \"Design a worm gear made of bronze with a worm gear ratio of 10:1.\",\n",
    "    \"Design a spur gear made of cast iron with a module of 2.5 mm.\",\n",
    "\n",
    "    # **Dimensions:**\n",
    "    \"Design a gear with a diameter of 50 mm and a face width of 10 mm.\",\n",
    "    \"Design a gear with a pitch diameter of 30 mm and a circular pitch of 6 mm.\",\n",
    "    \"Design a gear with a center distance of 200 mm and a gear ratio of 3:1.\",\n",
    "\n",
    "    # **Constraints and Applications:**\n",
    "    \"Design a gear for a high-speed application with minimal backlash requirement.\",\n",
    "    \"Design a gear for an application with limited space that needs to be lightweight.\",\n",
    "    \"Design a gear for a noisy environment that needs to operate quietly.\",\n",
    "    \"Design a gear for a low-speed application with a high torque requirement.\",\n",
    "    \"Design a gear for an application subject to shock loads that needs to be durable.\",\n",
    "    \"Design a gear for a food processing application that requires corrosion resistance.\",\n",
    "    \"Design a gear for a medical device that needs to be sterilizable.\",\n",
    "    \"Design a gear for a robotic arm with a high degree of accuracy needed.\",\n",
    "\n",
    "    # **Combinations:**\n",
    "    \"Design a spur gear for a load of 500N and a speed of 1000rpm.\",\n",
    "    \"Design a bevel gear for a torque of 100Nm and a gear ratio of 3:2.\",\n",
    "    \"Design a worm gear to transmit power of 2kW with an efficiency of 85%.\",\n",
    "    \"Design a helical gear with a pressure angle of 30 degrees and a module of 3 mm.\",\n",
    "    \"Design a gear with a diameter of 75 mm and a face width of 15 mm for a high-torque application.\",\n",
    "\n",
    "    # **Variations:**\n",
    "    \"Design a gear with a different number of teeth (beyond 20) based on specific constraints.\",\n",
    "    \"Design a gear with a different gear ratio based on desired speed and torque requirements.\",\n",
    "    \"Design a gear with a different material based on application-specific needs (e.g., aluminum, plastic).\",\n",
    "    \"Design a gear with a different pressure angle for optimized performance.\",\n",
    "    \"Design a gear with a different module based on desired size and strength.\",\n",
    "\n",
    "    # **Additional Considerations:**\n",
    "    \"Design a gear that is self-lubricating.\",\n",
    "    \"Design a gear that is back-drivable.\",\n",
    "    \"Design a gear with a clutch mechanism.\",\n",
    "    \"Design a gear with a variable gear ratio.\",\n",
    "    \"Design a gear with multiple teeth per pitch (e.g., internal gear).\",\n",
    "\n",
    "    # **Applications:**\n",
    "    \"Design a gear for a conveyor belt.\",\n",
    "    \"Design a gear for a bicycle.\",\n",
    "    \"Design a gear for a wind turbine.\",\n",
    "    \"Design a gear for a gear pump.\",\n",
    "    \"Design a gear for a 3D printer.\",\n",
    "    \"Design a gear for a clock.\",\n",
    "    \"Design a gear for a washing machine.\",\n",
    "    \"Design a gear for a blender.\",\n",
    "    \"Design a gear for a drill.\",\n",
    "    \"Design a gear for a power saw.\",\n",
    "\n",
    "    # **Advanced:**\n",
    "    \"Design a gear set for a multi-speed transmission.\",\n",
    "    \"Design a gear train for a specific power transmission ratio.\",\n",
    "    \"Design a gear system with an idler gear.\",\n",
    "    \"Design a gear system with a compound gear train.\",\n",
    "    \"Design a gear system for a planetary gear set.\",\n",
    "\n",
    "    # **Real-World Examples:**\n",
    "    \"Design a gear similar to the one found in a specific car model's transmission.\",\n",
    "    \"Design a gear similar to the one used in a specific lawnmower engine.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PDF and preprocess the text\n",
    "pdf_path = '/home/rithwik/paper/dataset/shigley_cleaned_text.txt'  # Replace with your PDF path\n",
    "text = open(pdf_path, 'r')\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens({'pad_token': '<pad>'})  # Set padding token\n",
    "config = GPT2Config.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=config)\n",
    "\n",
    "# Prepare dataset and fine-tune GPT-2\n",
    "gear_dataset = GearDataset(text)\n",
    "fine_tune_gpt2(gear_dataset, tokenizer, model, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in prompts:\n",
    "    input_text = \"<BOS> \" + prompt  # Beginning of sequence token\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    # Generate output\n",
    "    output = model.generate(input_ids=input_ids, max_length=100, temperature=0.7, num_return_sequences=1)\n",
    "    output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(\"Generated Gear Design:\", output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
